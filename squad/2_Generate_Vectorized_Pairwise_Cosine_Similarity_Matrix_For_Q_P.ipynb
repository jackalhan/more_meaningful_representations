{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_type = 'train'\n",
    "dataset_type = 'dev'\n",
    "dataset_version = 'v1.1'\n",
    "\n",
    "index_field = ['Unnamed: 0']\n",
    "\n",
    "# required files\n",
    "_basepath = '/home/jackalhan/Development/github/bilm-tf/squad'\n",
    "datadir = os.path.join(_basepath, dataset_type)\n",
    "modeldir = os.path.join(_basepath, 'model')\n",
    "\n",
    "_qas_file_name = '{}_qas.csv'.format(dataset_type)\n",
    "qas_file = os.path.join(datadir, _qas_file_name)\n",
    "\n",
    "_embedding_mean_paragraph_file_as_h5py_name = 'elmo_mean_paragraph_embeddings.hdf5'\n",
    "embedding_mean_paragraph_file_as_h5py = os.path.join(datadir, _embedding_mean_paragraph_file_as_h5py_name)\n",
    "\n",
    "_embedding_mean_question_file_as_h5py_name = 'elmo_mean_question_embeddings.hdf5'\n",
    "embedding_mean_question_file_as_h5py = os.path.join(datadir, _embedding_mean_question_file_as_h5py_name)\n",
    "\n",
    "_cos_similarity_results_file_name =  '{}_cos_similarity_q_vs_para.csv'.format(dataset_type)\n",
    "cos_similarity_results_file_name = os.path.join(datadir, _cos_similarity_results_file_name)\n",
    "\n",
    "df_qas = pd.read_csv(qas_file).set_index(index_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 1024\n",
    "items = [dict({'type':'question', \n",
    "                     'matrix': np.empty((0, dims), dtype=float), \n",
    "                     'source_file':embedding_mean_question_file_as_h5py\n",
    "                     }), \n",
    "              dict({'type':'paragraph', \n",
    "                     'matrix':np.empty((0, dims), dtype=float), \n",
    "                     'source_file':embedding_mean_paragraph_file_as_h5py,\n",
    "                     })\n",
    "              ]\n",
    "\n",
    "for vals in items:\n",
    "    print(vals['type'], 'is getting processed!!!')\n",
    "    with h5py.File(vals['source_file'], 'r') as fin:        \n",
    "        for _ in tqdm_notebook(fin, total=len(fin)):             \n",
    "            vec = np.reshape(np.array(fin[str(_)][...]), (1,dims))                                   \n",
    "            vals['matrix'] = np.append(vals['matrix'], vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUES = items[0]['matrix']\n",
    "print('QUES', QUES.shape)\n",
    "PARA = items[1]['matrix']\n",
    "print('PARA', PARA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for q_id, _ in enumerate(tqdm_notebook(QUES, total=len(QUES))):\n",
    "    q_vec = np.array([_]) \n",
    "    sk_sim = cosine_similarity(q_vec,PARA)[0]\n",
    "    actual_paragraph_id = df_qas[df_qas['Question_Id'] == q_id]['Paragraph_Id'].values[0]\n",
    "    similarities = np.argsort(-sk_sim)\n",
    "    order_of_the_actual_paragraph_id = np.where(similarities == actual_paragraph_id)[0][0] + 1\n",
    "    calculated_most_similar_1_paragraph = similarities[0]\n",
    "    results.append((q_id, actual_paragraph_id,  order_of_the_actual_paragraph_id, sk_sim[actual_paragraph_id], calculated_most_similar_1_paragraph, sk_sim[calculated_most_similar_1_paragraph]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results= pd.DataFrame(data=results, columns=['Question_Id', 'Actual_Paragraph_Id', \n",
    "                                                 'Order Index of Actual_Paragraph_Id in Similarities List',\n",
    "                                                 'Similarity Score for Actual_Paragraph_Id'\n",
    "                                                 'Calculated Top 1 Most Similar Paragraph', \n",
    "                                                 'Similarity Score for Most Similar Paragraph'\n",
    "                                                ])\n",
    "df_results.to_csv(cos_similarity_results_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(cos_similarity_results_file_name).set_index('Question_Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_results['Order Index of Actual_Paragraph_Id in Similarities List']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x, bins=range(min(x), max(x) + 1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
