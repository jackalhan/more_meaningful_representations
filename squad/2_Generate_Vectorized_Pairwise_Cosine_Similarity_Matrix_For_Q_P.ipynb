{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_type = 'train'\n",
    "dataset_type = 'dev'\n",
    "dataset_version = 'v1.1'\n",
    "\n",
    "index_field = ['Unnamed: 0']\n",
    "\n",
    "# required files\n",
    "_basepath = '/home/jackalhan/Development/github/more_meaningful_representations/squad/'\n",
    "datadir = os.path.join(_basepath, dataset_type)\n",
    "modeldir = os.path.join(_basepath, 'model')\n",
    "\n",
    "_qas_file_name = '{}_qas.csv'.format(dataset_type)\n",
    "qas_file = os.path.join(datadir, _qas_file_name)\n",
    "\n",
    "_embedding_mean_paragraph_file_as_h5py_name = 'elmo_{}_mean_paragraph_embeddings.hdf5'\n",
    "embedding_mean_paragraph_file_as_h5py = os.path.join(datadir, _embedding_mean_paragraph_file_as_h5py_name)\n",
    "\n",
    "_embedding_mean_question_file_as_h5py_name = 'elmo_{}_mean_question_embeddings.hdf5'\n",
    "embedding_mean_question_file_as_h5py = os.path.join(datadir, _embedding_mean_question_file_as_h5py_name)\n",
    "\n",
    "_cos_similarity_results_file_name =  '{}_cos_similarity_with_{}_norm_for_q_vs_para.csv'\n",
    "cos_similarity_results_file_name = os.path.join(datadir, _cos_similarity_results_file_name)\n",
    "\n",
    "_cos_similarity_results_as_hist_file_name =  'histogram_{}_cos_similarity_with_{}_norm_for_q_vs_para.png'\n",
    "cos_similarity_results_as_hist_file = os.path.join(datadir, _cos_similarity_results_as_hist_file_name)\n",
    "\n",
    "\n",
    "df_qas = pd.read_csv(qas_file).set_index(index_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 1024\n",
    "items = [dict({'type':'questions', \n",
    "                     'source_file':embedding_mean_question_file_as_h5py\n",
    "                     }), \n",
    "              dict({'type':'paragraphs', \n",
    "                     'source_file':embedding_mean_paragraph_file_as_h5py,\n",
    "                     })\n",
    "              ]\n",
    "\n",
    "for norm_type in ['l2']:\n",
    "    print(10*'*', norm_type.upper(),'NORM', 10*'*')\n",
    "    for vals in items:\n",
    "        print(vals['type'], 'are getting processed!!!')\n",
    "        vals['matrix'] = np.empty((0, dims), dtype=float)\n",
    "        with h5py.File(vals['source_file'].format(norm_type), 'r') as fin:        \n",
    "            for _ in tqdm_notebook(fin, total=len(fin)):             \n",
    "                vec = np.reshape(np.array(fin[str(_)][...]), (1,dims))                                   \n",
    "                vals['matrix'] = np.append(vals['matrix'], vec, axis=0)\n",
    "            \n",
    "    QUES = items[0]['matrix']\n",
    "    print('QUES Shape', QUES.shape)\n",
    "    PARA = items[1]['matrix']\n",
    "    print('PARA Shape', PARA.shape)\n",
    "    print('Similarities are getting calculated !!!')\n",
    "    results = []\n",
    "    for q_id, _ in enumerate(tqdm_notebook(QUES, total=len(QUES-1))):\n",
    "        q_vec = np.array([_]) \n",
    "        sk_sim = cosine_similarity(q_vec,PARA)[0]\n",
    "        actual_paragraph_id = df_qas[df_qas['Question_Id'] == q_id]['Paragraph_Id'].values[0]\n",
    "        similarities = np.argsort(-sk_sim)\n",
    "        order_of_the_actual_paragraph_id = np.where(similarities == actual_paragraph_id)[0][0] + 1\n",
    "        calculated_most_similar_1_paragraph = similarities[0]\n",
    "        results.append((q_id, actual_paragraph_id,  order_of_the_actual_paragraph_id, sk_sim[actual_paragraph_id], calculated_most_similar_1_paragraph, sk_sim[calculated_most_similar_1_paragraph]))\n",
    "    \n",
    "    df_results= pd.DataFrame(data=results, columns=['Question_Id', 'Actual_Paragraph_Id', \n",
    "                                                 'Order Index of Actual_Paragraph_Id in Similarities List',\n",
    "                                                 'Similarity Score for Actual_Paragraph_Id',\n",
    "                                                 'Calculated Top 1 Most Similar Paragraph', \n",
    "                                                 'Similarity Score for Most Similar Paragraph'\n",
    "                                                ])\n",
    "    df_results.to_csv(cos_similarity_results_file_name.format(dataset_type, norm_type), index=False)\n",
    "    ax = df_results['Order Index of Actual_Paragraph_Id in Similarities List'].hist(bins=range(min(df_results['Order Index of Actual_Paragraph_Id in Similarities List']), max(df_results['Order Index of Actual_Paragraph_Id in Similarities List']) + 1, 1))\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(cos_similarity_results_as_hist_file.format(dataset_type, norm_type))\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
