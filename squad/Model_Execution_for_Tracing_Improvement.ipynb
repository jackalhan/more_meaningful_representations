{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path = !echo ${VIRTUAL_ENV}\n",
    "path = os.path.join(path[0], '..')\n",
    "sys.path.append(path)\n",
    "from helper.utils import load_from_pickle, load_from_shelve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import tools\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#import impywidgets as widget\n",
    "py.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_path = \"/home/jackalhan/Development/github/more_meaningful_representations/squad/train/improvement/model_performances/subset_5000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 --> /home/jackalhan/Development/github/more_meaningful_representations/squad/train/improvement/model_performances/subset_5000/model_2_layers_6_epoch_100_mar_0.6_sf_0.1_0.1_0.1_0.1_0.1_0.1_wd_0.001_0.001_0.001_0.001_0.001_0.001_lr_0.001_dim_2048_2048_2048_2048_2048_2048_keep_1_1_1_1_1_1_seed_66_66_66_66_66_66_loss_v3/debug_dict.pkl',\n",
       " '2 --> /home/jackalhan/Development/github/more_meaningful_representations/squad/train/improvement/model_performances/subset_5000/ELMO_model_2_layers_6_epoch_100_mar_0.6_sf_0.1_0.1_0.1_0.1_0.1_0.1_wd_0.001_0.001_0.001_0.001_0.001_0.001_lr_0.001_dim_2048_2048_2048_2048_2048_2048_keep_1_1_1_1_1_1_seed_66_66_66_66_66_66_loss_v3/debug_dict.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_files = {}\n",
    "for i, structure in enumerate(os.walk(base_data_path)):\n",
    "    root, dirs, files = structure\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):            \n",
    "            debug_files[i] = os.path.join(root, file)\n",
    "[\"{} --> {}\".format(key, value) for key, value in debug_files.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jackalhan/Development/github/more_meaningful_representations/squad/train/improvement/model_performances/subset_5000/model_2_layers_6_epoch_100_mar_0.6_sf_0.1_0.1_0.1_0.1_0.1_0.1_wd_0.001_0.001_0.001_0.001_0.001_0.001_lr_0.001_dim_2048_2048_2048_2048_2048_2048_keep_1_1_1_1_1_1_seed_66_66_66_66_66_66_loss_v3/debug_dict.pkl'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_indx =1\n",
    "my_dict = load_from_pickle(os.path.join(base_data_path, \n",
    "                                        debug_files[model_indx]))\n",
    "num_of_epochs = my_dict['epochs']\n",
    "number_of_sample_question_size = 15\n",
    "# temp_ids = np.arange(my_dict['actual_labels'].shape[0])\n",
    "# np.random.shuffle(temp_ids)\n",
    "# question_ids = temp_ids[:number_of_sample_question_size]\n",
    "debug_files[model_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"383c5434-565c-4423-a9e4-81b6822778fe\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "        Plotly.plot(\n",
       "            '383c5434-565c-4423-a9e4-81b6822778fe',\n",
       "            [{\"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"name\": \"Top top_1\", \"y\": [0.0006, 0.007, 0.0116, 0.015, 0.0166, 0.0182, 0.02, 0.0204, 0.0212, 0.0212, 0.0208, 0.021, 0.0218, 0.0224, 0.0226, 0.0228, 0.0226, 0.022, 0.0222, 0.0226, 0.0216, 0.0224, 0.0224, 0.0222, 0.0216, 0.0216, 0.0214, 0.0218, 0.022, 0.022, 0.0222, 0.0208, 0.0218, 0.0222, 0.0218, 0.0224, 0.0224, 0.0222, 0.0224, 0.0226, 0.0224, 0.0234, 0.024, 0.0234, 0.0238, 0.0234, 0.0236, 0.0242, 0.0238, 0.0232, 0.0232, 0.023, 0.022, 0.0224, 0.0226, 0.0232, 0.023, 0.023, 0.0234, 0.0242, 0.0234, 0.023, 0.0234, 0.024, 0.0236, 0.0232, 0.0238, 0.0232, 0.0236, 0.0228, 0.0236, 0.0232, 0.0234, 0.0236, 0.0224, 0.0222, 0.0238, 0.023, 0.0228, 0.023, 0.0234, 0.0236, 0.0238, 0.0238, 0.023, 0.0242, 0.0238, 0.0242, 0.0236, 0.0238, 0.0236, 0.0238, 0.023, 0.0224, 0.0224, 0.0236, 0.0228, 0.0228, 0.0232, 0.0228, 0.0228], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"uid\": \"fa9093ae-aa39-11e8-b96f-989096cb06e5\"}, {\"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"name\": \"Top top_2\", \"y\": [0.001, 0.0118, 0.0184, 0.0254, 0.0274, 0.0308, 0.0322, 0.032, 0.0336, 0.0336, 0.0338, 0.0332, 0.0334, 0.0318, 0.0324, 0.032, 0.0324, 0.033, 0.0336, 0.033, 0.0332, 0.0338, 0.0348, 0.035, 0.035, 0.035, 0.0366, 0.0366, 0.0364, 0.0372, 0.0356, 0.0346, 0.0356, 0.035, 0.0352, 0.0358, 0.0358, 0.0358, 0.0364, 0.0366, 0.0376, 0.0366, 0.0372, 0.0378, 0.038, 0.038, 0.0378, 0.0382, 0.0388, 0.0388, 0.0384, 0.037, 0.0384, 0.037, 0.0382, 0.038, 0.0382, 0.0384, 0.0372, 0.0388, 0.0376, 0.038, 0.0376, 0.0388, 0.0374, 0.0376, 0.038, 0.0378, 0.0374, 0.038, 0.0382, 0.0368, 0.0372, 0.0366, 0.0372, 0.0384, 0.0364, 0.0376, 0.0376, 0.0372, 0.0378, 0.0368, 0.038, 0.0388, 0.0374, 0.0374, 0.038, 0.0384, 0.039, 0.039, 0.0388, 0.038, 0.0386, 0.0382, 0.0376, 0.038, 0.0386, 0.0384, 0.039, 0.0386, 0.0384], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"uid\": \"fa9093af-aa39-11e8-b96f-989096cb06e5\"}, {\"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"name\": \"Top top_5\", \"y\": [0.0022, 0.0214, 0.034, 0.042, 0.0458, 0.0494, 0.0516, 0.0522, 0.0542, 0.055, 0.0552, 0.0538, 0.0552, 0.0556, 0.0558, 0.0564, 0.0576, 0.0576, 0.0568, 0.058, 0.0582, 0.0578, 0.0584, 0.0592, 0.0594, 0.0594, 0.0596, 0.0592, 0.0602, 0.0608, 0.0608, 0.0618, 0.0618, 0.0622, 0.061, 0.0622, 0.063, 0.0626, 0.0632, 0.0624, 0.0624, 0.0618, 0.0618, 0.0608, 0.0624, 0.0632, 0.0626, 0.0632, 0.0624, 0.0624, 0.0622, 0.0632, 0.061, 0.062, 0.0622, 0.062, 0.0626, 0.0624, 0.0624, 0.0628, 0.0634, 0.0632, 0.0644, 0.0638, 0.0634, 0.062, 0.0624, 0.0644, 0.0632, 0.0636, 0.064, 0.0636, 0.0638, 0.064, 0.0642, 0.063, 0.0636, 0.0654, 0.0662, 0.0662, 0.066, 0.0666, 0.0664, 0.066, 0.0652, 0.0658, 0.0664, 0.0664, 0.0666, 0.0666, 0.0678, 0.0666, 0.0674, 0.0678, 0.0664, 0.067, 0.067, 0.0672, 0.0676, 0.0674, 0.0672], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"uid\": \"fa9093b0-aa39-11e8-b96f-989096cb06e5\"}, {\"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"name\": \"Top top_10\", \"y\": [0.0036, 0.0322, 0.05, 0.0594, 0.0662, 0.07, 0.073, 0.074, 0.0752, 0.0752, 0.077, 0.0796, 0.0814, 0.0802, 0.0818, 0.0842, 0.0848, 0.0858, 0.0838, 0.084, 0.084, 0.0842, 0.0834, 0.0854, 0.0854, 0.0862, 0.0876, 0.0876, 0.088, 0.0884, 0.0892, 0.0898, 0.09, 0.09, 0.0906, 0.0894, 0.0912, 0.0906, 0.0908, 0.091, 0.0914, 0.0916, 0.0908, 0.0906, 0.0906, 0.0914, 0.0926, 0.0914, 0.0918, 0.0918, 0.092, 0.0922, 0.0936, 0.0936, 0.094, 0.0934, 0.0936, 0.0944, 0.0926, 0.094, 0.0942, 0.0952, 0.095, 0.0948, 0.0952, 0.0964, 0.0952, 0.0946, 0.0938, 0.0956, 0.0954, 0.096, 0.0952, 0.0958, 0.096, 0.0966, 0.096, 0.0966, 0.0956, 0.0974, 0.0978, 0.0972, 0.0966, 0.097, 0.0968, 0.096, 0.098, 0.0976, 0.0974, 0.0982, 0.0978, 0.0974, 0.0972, 0.0974, 0.0978, 0.0968, 0.0972, 0.096, 0.0964, 0.096, 0.0962], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"uid\": \"fa9093b1-aa39-11e8-b96f-989096cb06e5\"}, {\"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"name\": \"Top top_20\", \"y\": [0.0062, 0.0494, 0.0754, 0.0818, 0.0926, 0.097, 0.1022, 0.1044, 0.1082, 0.1112, 0.1126, 0.1138, 0.1128, 0.114, 0.1154, 0.114, 0.1172, 0.118, 0.1174, 0.1218, 0.1212, 0.124, 0.1236, 0.1248, 0.1242, 0.1246, 0.1246, 0.125, 0.1262, 0.126, 0.1258, 0.128, 0.1284, 0.127, 0.1294, 0.1288, 0.1284, 0.1298, 0.1298, 0.13, 0.1286, 0.1268, 0.128, 0.129, 0.1306, 0.1298, 0.1298, 0.1312, 0.1312, 0.1304, 0.1316, 0.1308, 0.1306, 0.1326, 0.1314, 0.1326, 0.1328, 0.1322, 0.1322, 0.1322, 0.1328, 0.1326, 0.1324, 0.1332, 0.1324, 0.1334, 0.1344, 0.1336, 0.1336, 0.1326, 0.1342, 0.1328, 0.1342, 0.1344, 0.132, 0.134, 0.1344, 0.1326, 0.1352, 0.1342, 0.1342, 0.1332, 0.1366, 0.1344, 0.1342, 0.137, 0.1348, 0.136, 0.1346, 0.1352, 0.1346, 0.1346, 0.1338, 0.134, 0.1348, 0.1334, 0.1348, 0.1344, 0.135, 0.1342, 0.1342], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"uid\": \"fa9093b2-aa39-11e8-b96f-989096cb06e5\"}, {\"x\": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"name\": \"Top top_50\", \"y\": [0.0124, 0.0864, 0.116, 0.1332, 0.1424, 0.1516, 0.1596, 0.1642, 0.1698, 0.1696, 0.1688, 0.1704, 0.1704, 0.172, 0.174, 0.1756, 0.1788, 0.1784, 0.1804, 0.1802, 0.1836, 0.184, 0.1854, 0.1862, 0.1864, 0.1856, 0.1854, 0.1846, 0.1856, 0.1882, 0.1872, 0.188, 0.1884, 0.1886, 0.1892, 0.1894, 0.1894, 0.1898, 0.1904, 0.1906, 0.1908, 0.1902, 0.1908, 0.1906, 0.192, 0.1928, 0.1928, 0.1924, 0.1932, 0.1926, 0.1922, 0.1936, 0.1946, 0.1948, 0.1956, 0.1946, 0.1946, 0.1948, 0.1952, 0.1962, 0.196, 0.1946, 0.195, 0.1948, 0.1966, 0.1964, 0.1964, 0.1954, 0.197, 0.1966, 0.1978, 0.197, 0.1982, 0.199, 0.1978, 0.1976, 0.1994, 0.199, 0.1996, 0.1994, 0.199, 0.1986, 0.2012, 0.2004, 0.2006, 0.2014, 0.2002, 0.2006, 0.2008, 0.2006, 0.201, 0.2016, 0.2016, 0.201, 0.2014, 0.2004, 0.2022, 0.201, 0.2006, 0.2018, 0.1996], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"uid\": \"fa9093b3-aa39-11e8-b96f-989096cb06e5\"}],\n",
       "            {\"title\": \"How the recalls at top n are changing for each epoch\", \"yaxis\": {\"title\": \"Recall Values\"}, \"xaxis\": {\"title\": \"Epochs\"}},\n",
       "            {\"linkText\": \"Export to plot.ly\", \"showLink\": true}\n",
       "        ).then(function () {return Plotly.addFrames('383c5434-565c-4423-a9e4-81b6822778fe',{});}).then(function(){Plotly.animate('383c5434-565c-4423-a9e4-81b6822778fe');})\n",
       "        });</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "How the recalls at top n are changing for each epoch \n",
    "\"\"\"\n",
    "\n",
    "data_recalls = []\n",
    "sub_list = []\n",
    "sub_list.append(0)\n",
    "sub_list.extend([x for x in my_dict['normalized_recalls_before_model']])\n",
    "data_recalls.append(sub_list)\n",
    "for i in range(1,num_of_epochs+1):\n",
    "    sub_list = []\n",
    "    sub_list.append(i)\n",
    "    sub_list.extend([x for x in my_dict[str(i)]['normalized_recalls_after_model']])\n",
    "    data_recalls.append(sub_list)\n",
    "df_data_recalls = pd.DataFrame(data_recalls, columns=['epoch', 'top_1', 'top_2', 'top_5'\n",
    "                                                   ,'top_10', 'top_20', 'top_50'])\n",
    "traces = []\n",
    "for c in df_data_recalls.columns[1:]:\n",
    "    trace = go.Scatter(\n",
    "    x = df_data_recalls.index,\n",
    "    y = df_data_recalls[c],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Top {}'.format(c))\n",
    "    traces.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='How the recalls at top n are changing for each epoch',\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Recall Values'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=traces, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90     0.093933\n",
       "89     0.093900\n",
       "87     0.093867\n",
       "82     0.093767\n",
       "96     0.093767\n",
       "91     0.093667\n",
       "88     0.093667\n",
       "85     0.093633\n",
       "98     0.093633\n",
       "92     0.093600\n",
       "86     0.093533\n",
       "93     0.093467\n",
       "99     0.093467\n",
       "83     0.093400\n",
       "94     0.093400\n",
       "97     0.093300\n",
       "95     0.093200\n",
       "100    0.093067\n",
       "80     0.093033\n",
       "79     0.092900\n",
       "84     0.092867\n",
       "78     0.092833\n",
       "81     0.092667\n",
       "77     0.092367\n",
       "76     0.092267\n",
       "73     0.092233\n",
       "70     0.092200\n",
       "72     0.092000\n",
       "75     0.091967\n",
       "66     0.091700\n",
       "         ...   \n",
       "30     0.086800\n",
       "28     0.086400\n",
       "26     0.085867\n",
       "27     0.085800\n",
       "23     0.085467\n",
       "25     0.085400\n",
       "24     0.085333\n",
       "22     0.084667\n",
       "21     0.084367\n",
       "20     0.083633\n",
       "19     0.083267\n",
       "17     0.082467\n",
       "18     0.082367\n",
       "16     0.082233\n",
       "15     0.080833\n",
       "14     0.080333\n",
       "13     0.079333\n",
       "12     0.079167\n",
       "11     0.078633\n",
       "10     0.078033\n",
       "9      0.077633\n",
       "8      0.077033\n",
       "7      0.074533\n",
       "6      0.073100\n",
       "5      0.069500\n",
       "4      0.065167\n",
       "3      0.059467\n",
       "2      0.050900\n",
       "1      0.034700\n",
       "0      0.004333\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_recalls[['top_1', 'top_2', 'top_5','top_10', 'top_20', 'top_50']].mean(axis=1).sort_values(ascending =[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_20</th>\n",
       "      <th>top_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>0.1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.1336</td>\n",
       "      <td>0.1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1284</td>\n",
       "      <td>0.1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.1704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.1698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.1704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch   top_1   top_2   top_5  top_10  top_20  top_50\n",
       "59     59  0.0242  0.0388  0.0628  0.0940  0.1322  0.1962\n",
       "87     87  0.0242  0.0384  0.0664  0.0976  0.1360  0.2006\n",
       "47     47  0.0242  0.0382  0.0632  0.0914  0.1312  0.1924\n",
       "85     85  0.0242  0.0374  0.0658  0.0960  0.1370  0.2014\n",
       "63     63  0.0240  0.0388  0.0638  0.0948  0.1332  0.1948\n",
       "42     42  0.0240  0.0372  0.0618  0.0908  0.1280  0.1908\n",
       "89     89  0.0238  0.0390  0.0666  0.0982  0.1352  0.2006\n",
       "83     83  0.0238  0.0388  0.0660  0.0970  0.1344  0.2004\n",
       "48     48  0.0238  0.0388  0.0624  0.0918  0.1312  0.1932\n",
       "91     91  0.0238  0.0380  0.0666  0.0974  0.1346  0.2016\n",
       "86     86  0.0238  0.0380  0.0664  0.0980  0.1348  0.2002\n",
       "82     82  0.0238  0.0380  0.0664  0.0966  0.1366  0.2012\n",
       "66     66  0.0238  0.0380  0.0624  0.0952  0.1344  0.1964\n",
       "44     44  0.0238  0.0380  0.0624  0.0906  0.1306  0.1920\n",
       "76     76  0.0238  0.0364  0.0636  0.0960  0.1344  0.1994\n",
       "88     88  0.0236  0.0390  0.0666  0.0974  0.1346  0.2008\n",
       "90     90  0.0236  0.0388  0.0678  0.0978  0.1346  0.2010\n",
       "70     70  0.0236  0.0382  0.0640  0.0954  0.1342  0.1978\n",
       "95     95  0.0236  0.0380  0.0670  0.0968  0.1334  0.2004\n",
       "46     46  0.0236  0.0378  0.0626  0.0926  0.1298  0.1928\n",
       "64     64  0.0236  0.0374  0.0634  0.0952  0.1324  0.1966\n",
       "68     68  0.0236  0.0374  0.0632  0.0938  0.1336  0.1970\n",
       "81     81  0.0236  0.0368  0.0666  0.0972  0.1332  0.1986\n",
       "73     73  0.0236  0.0366  0.0640  0.0958  0.1344  0.1990\n",
       "45     45  0.0234  0.0380  0.0632  0.0914  0.1298  0.1928\n",
       "80     80  0.0234  0.0378  0.0660  0.0978  0.1342  0.1990\n",
       "43     43  0.0234  0.0378  0.0608  0.0906  0.1290  0.1906\n",
       "62     62  0.0234  0.0376  0.0644  0.0950  0.1324  0.1950\n",
       "60     60  0.0234  0.0376  0.0634  0.0942  0.1328  0.1960\n",
       "72     72  0.0234  0.0372  0.0638  0.0952  0.1342  0.1982\n",
       "..    ...     ...     ...     ...     ...     ...     ...\n",
       "37     37  0.0222  0.0358  0.0626  0.0906  0.1298  0.1898\n",
       "30     30  0.0222  0.0356  0.0608  0.0892  0.1258  0.1872\n",
       "33     33  0.0222  0.0350  0.0622  0.0900  0.1270  0.1886\n",
       "23     23  0.0222  0.0350  0.0592  0.0854  0.1248  0.1862\n",
       "18     18  0.0222  0.0336  0.0568  0.0838  0.1174  0.1804\n",
       "52     52  0.0220  0.0384  0.0610  0.0936  0.1306  0.1946\n",
       "29     29  0.0220  0.0372  0.0608  0.0884  0.1260  0.1882\n",
       "28     28  0.0220  0.0364  0.0602  0.0880  0.1262  0.1856\n",
       "17     17  0.0220  0.0330  0.0576  0.0858  0.1180  0.1784\n",
       "27     27  0.0218  0.0366  0.0592  0.0876  0.1250  0.1846\n",
       "32     32  0.0218  0.0356  0.0618  0.0900  0.1284  0.1884\n",
       "34     34  0.0218  0.0352  0.0610  0.0906  0.1294  0.1892\n",
       "12     12  0.0218  0.0334  0.0552  0.0814  0.1128  0.1704\n",
       "25     25  0.0216  0.0350  0.0594  0.0862  0.1246  0.1856\n",
       "24     24  0.0216  0.0350  0.0594  0.0854  0.1242  0.1864\n",
       "20     20  0.0216  0.0332  0.0582  0.0840  0.1212  0.1836\n",
       "26     26  0.0214  0.0366  0.0596  0.0876  0.1246  0.1854\n",
       "9       9  0.0212  0.0336  0.0550  0.0752  0.1112  0.1696\n",
       "8       8  0.0212  0.0336  0.0542  0.0752  0.1082  0.1698\n",
       "11     11  0.0210  0.0332  0.0538  0.0796  0.1138  0.1704\n",
       "31     31  0.0208  0.0346  0.0618  0.0898  0.1280  0.1880\n",
       "10     10  0.0208  0.0338  0.0552  0.0770  0.1126  0.1688\n",
       "7       7  0.0204  0.0320  0.0522  0.0740  0.1044  0.1642\n",
       "6       6  0.0200  0.0322  0.0516  0.0730  0.1022  0.1596\n",
       "5       5  0.0182  0.0308  0.0494  0.0700  0.0970  0.1516\n",
       "4       4  0.0166  0.0274  0.0458  0.0662  0.0926  0.1424\n",
       "3       3  0.0150  0.0254  0.0420  0.0594  0.0818  0.1332\n",
       "2       2  0.0116  0.0184  0.0340  0.0500  0.0754  0.1160\n",
       "1       1  0.0070  0.0118  0.0214  0.0322  0.0494  0.0864\n",
       "0       0  0.0006  0.0010  0.0022  0.0036  0.0062  0.0124\n",
       "\n",
       "[101 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_recalls.sort_values(by=['top_1', 'top_2', 'top_5', 'top_10', 'top_20', 'top_50'], ascending =[False, False, False, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"588bedee-ed31-45e7-9830-1d860fa00148\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"588bedee-ed31-45e7-9830-1d860fa00148\", [{\"name\": \"Question 1550\", \"y\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Question 4257\", \"y\": [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Question 459\", \"y\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}], {\"title\": \"Questions\\\" Paragraphs are still in their top 1 closest neighbours\", \"xaxis\": {\"title\": \"Epochs\"}, \"yaxis\": {\"title\": \"Yes or No\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problematic Questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4257]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "which of questions are getting worse (moving farther from its ground-truth) through subsequent epochs.\n",
    "\"\"\"\n",
    "\n",
    "k = 1\n",
    "good_questions_at_top_1_idx = np.where(my_dict['top_k'][str(k)]['are_founds_before'] == 1)\n",
    "np.random.shuffle(good_questions_at_top_1_idx[0])\n",
    "# IN ORDER TO SELECT RANDOM QUESTIONS\n",
    "#question_ids = good_questions_at_top_1_idx[0][:number_of_sample_question_size]\n",
    "\n",
    "# IN ORDER TO ENTER QUESTIONS\n",
    "question_ids = [1550, 4257, 459]\n",
    "\n",
    "good_questions_at_top_1_are_founds = my_dict['top_k'][str(k)]['are_founds_before'][question_ids]\n",
    "good_questions_at_top_1_labels = my_dict['top_k'][str(k)]['closest_labels_before'][question_ids]\n",
    "good_questions_at_top_1_distances = my_dict['top_k'][str(k)]['distances_before'][question_ids]\n",
    "\n",
    "still_good_question = pd.DataFrame()\n",
    "still_good_question[0]= np.reshape(good_questions_at_top_1_are_founds, [-1,])\n",
    "for i in range(1,num_of_epochs+1):\n",
    "    still_good_question[i] = np.reshape(my_dict[str(i)]['top_k'][str(k)]['are_founds_after'][question_ids], [-1,])\n",
    "still_good_question = still_good_question.T\n",
    "still_good_question.columns = [question_ids[col_name] for col_name in still_good_question.columns]\n",
    "data = []\n",
    "problematic_questions = []\n",
    "for q in question_ids:\n",
    "    _problematic_question = np.where(still_good_question[q] == 0)[0]\n",
    "    _problematic_question = still_good_question[q][_problematic_question]\n",
    "    if _problematic_question.shape[0] != 0:\n",
    "        problematic_questions.append(_problematic_question.name)\n",
    "    trace = go.Scatter(\n",
    "    x = still_good_question.index,\n",
    "    y = still_good_question[q],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Question {}'.format(q))\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Questions\" Paragraphs are still in their top {} closest neighbours'.format(k),\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Yes or No'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)\n",
    "print('Problematic Questions')\n",
    "[_p for _p in problematic_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"9adc5810-a927-4a7c-9e8d-a454843f4719\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"9adc5810-a927-4a7c-9e8d-a454843f4719\", [{\"name\": \"Question 4257\", \"y\": [1.1156939268112183, 1.0891761779785156, 1.080679178237915, 1.0748649835586548, 1.0692826509475708, 1.063838005065918, 1.0584940910339355, 1.0527433156967163, 1.0472393035888672, 1.041854739189148, 1.036456823348999], \"hoverinfo\": \"ytext\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"text\": [16065, 16065, 16065, 16065, 16065, 16065, 18823, 18823, 18823, 18823, 18823], \"type\": \"scatter\", \"mode\": \"lines+markers\"}], {\"title\": \"Are questions getting farther from their ground-truth paragraph in each epoch iteration? <br> to grab the closest paragraph, please hover the question\", \"xaxis\": {\"title\": \"Epochs\"}, \"yaxis\": {\"title\": \"Distance to Closest Paragraph\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Paragraphs of these Problematic Questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{4257: {16065, 18823}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"What happened to the following question?\"\n",
    "sample_question_that_are_getting_worse_idx = problematic_questions\n",
    "sample_question_that_are_getting_worse_sub_idx = [np.where(question_ids==q)[0][0] for q in sample_question_that_are_getting_worse_idx]\n",
    "#label_of_sample_question = good_questions_at_top_1_labels[sample_question_that_are_getting_worse_sub_idx]\n",
    "\"Is that question getting farther from its ground-truth paragraph?\"\n",
    "getting_worse_distances = pd.DataFrame()\n",
    "getting_worse_labels = pd.DataFrame()\n",
    "getting_worse_distances[0] = np.reshape(good_questions_at_top_1_distances[sample_question_that_are_getting_worse_sub_idx], [-1,])\n",
    "getting_worse_labels[0] = np.reshape(good_questions_at_top_1_labels[sample_question_that_are_getting_worse_sub_idx], [-1,])\n",
    "for i in range(1,num_of_epochs+1):\n",
    "    getting_worse_distances[i] = np.reshape(my_dict[str(i)]['top_k'][str(1)]['distances_after'][sample_question_that_are_getting_worse_idx], [-1,])\n",
    "    getting_worse_labels[i] = np.reshape(my_dict[str(i)]['top_k'][str(1)]['closest_labels_after'][sample_question_that_are_getting_worse_idx], [-1,])\n",
    "\n",
    "getting_worse_distances = getting_worse_distances.T\n",
    "getting_worse_labels = getting_worse_labels.T\n",
    "getting_worse_distances.columns = [sample_question_that_are_getting_worse_idx[i] for i, col_name in enumerate(getting_worse_distances.columns)]\n",
    "getting_worse_labels.columns = [sample_question_that_are_getting_worse_idx[i] for i, col_name in enumerate(getting_worse_labels.columns)]\n",
    "\n",
    "data = []\n",
    "for q in sample_question_that_are_getting_worse_idx:\n",
    "    trace = go.Scatter(\n",
    "    x = getting_worse_distances.index,\n",
    "    y = getting_worse_distances[q],\n",
    "    text = getting_worse_labels[q],\n",
    "    hoverinfo = 'y' 'text',\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Question {}'.format(q))\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Are questions getting farther from their ground-truth paragraph in each epoch iteration? <br> ' +\n",
    "    'to grab the closest paragraph, please hover the question',\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Distance to Closest Paragraph'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)\n",
    "closest_paragraphs_of_problematic_questions = dict()\n",
    "print('Closest Paragraphs of these Problematic Questions')\n",
    "for _q in problematic_questions:\n",
    "    closest_paragraphs_of_problematic_questions[_q] = set(getting_worse_labels[_q]) \n",
    "closest_paragraphs_of_problematic_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Question 4257\n"
     ]
    }
   ],
   "source": [
    "total_ks = len(my_dict['top_k'])\n",
    "questions = []\n",
    "for question, paragraphs in closest_paragraphs_of_problematic_questions.items():\n",
    "    print('*' * 10)\n",
    "    print('Question {}'.format(question))    \n",
    "    # iterate each k for that question so that we can specify \n",
    "    # what are the closest paragraph to that question for each k, what is their distance\n",
    "    # and also what is the order of ground truth paragraph to that question  within the list of results in k and \n",
    "    # its distance\n",
    "    \n",
    "    # FOR EPOCH 0 : BEFORE APPENDIX\n",
    "    _epoch = 0\n",
    "    for _k in range(total_ks):\n",
    "        paragraph_at_k = my_dict['top_k'][str(total_ks)]['closest_labels_before'][question][_k]\n",
    "        q_to_p_distance_at_k = my_dict['top_k'][str(total_ks)]['distances_before'][question][_k]\n",
    "        is_ground_truth_in_k_range = my_dict['top_k'][str(_k+1)]['are_founds_before'][question][0]\n",
    "        questions.append((question,\n",
    "                         _epoch,\n",
    "                         _k+1,\n",
    "                         paragraph_at_k, \n",
    "                         q_to_p_distance_at_k,\n",
    "                         is_ground_truth_in_k_range\n",
    "        ))\n",
    "    # FOR EPOCH > 0 : AFTER APPENDIX\n",
    "    for _epoch in range(1,num_of_epochs+1):\n",
    "        for _k in range(total_ks):\n",
    "            paragraph_at_k = my_dict[str(_epoch)]['top_k'][str(total_ks)]['closest_labels_after'][question][_k]\n",
    "            q_to_p_distance_at_k = my_dict[str(_epoch)]['top_k'][str(total_ks)]['distances_after'][question][_k]\n",
    "            is_ground_truth_in_k_range = my_dict[str(_epoch)]['top_k'][str(_k+1)]['are_founds_after'][question][0]\n",
    "            questions.append((question,\n",
    "                             _epoch,\n",
    "                             _k+1,\n",
    "                             paragraph_at_k, \n",
    "                             q_to_p_distance_at_k,\n",
    "                             is_ground_truth_in_k_range\n",
    "            ))\n",
    "df_traced_questions = pd.DataFrame(questions, columns=['question_id','epoch', 'k', 'paragraph_id', 'distance_to_paragraph', 'is_ground_truth_in_k_range'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4257 is displayed with itsprogress within all epoch and k values\n"
     ]
    }
   ],
   "source": [
    "question_id_to_examine = 4257\n",
    "\n",
    "print('Question {} is displayed with itsprogress within all epoch and k values'.format(question_id_to_examine))\n",
    "question_to_display_progress = df_traced_questions[df_traced_questions['question_id'] == question_id_to_examine]\n",
    "# question_to_display_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4257 is plotted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"a7703ea5-a477-4897-b727-a2b2eacf40e5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a7703ea5-a477-4897-b727-a2b2eacf40e5\", [{\"name\": \"Paragraph 992\", \"y\": [1.5, 1.11888587474823, 1.1106618642807007, 1.1049100160598755, 1.0993480682373047, 1.0939167737960815, 1.0885815620422363, 1.0834903717041016, 1.078571081161499, 1.0737651586532593, 1.0689786672592163], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Ground Truth 16065\", \"y\": [1.1156939268112183, 1.0891761779785156, 1.080679178237915, 1.0748649835586548, 1.0692826509475708, 1.063838005065918, 1.058504343032837, 1.0534181594848633, 1.0485341548919678, 1.043791651725769, 1.0390580892562866], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 3170\", \"y\": [1.5, 1.1038439273834229, 1.0952013731002808, 1.0889607667922974, 1.0829044580459595, 1.076952576637268, 1.0710827112197876, 1.0654940605163574, 1.0600577592849731, 1.054747462272644, 1.049404501914978], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 13376\", \"y\": [1.5, 1.122875452041626, 1.1141784191131592, 1.1076706647872925, 1.1013474464416504, 1.0951484441757202, 1.0890380144119263, 1.083245873451233, 1.0776031017303467, 1.0720824003219604, 1.0665407180786133], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 18823\", \"y\": [1.5, 1.0921974182128906, 1.0832713842391968, 1.076825499534607, 1.070604681968689, 1.0644996166229248, 1.0584940910339355, 1.0527433156967163, 1.0472393035888672, 1.041854739189148, 1.036456823348999], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 16233\", \"y\": [1.5, 1.1204930543899536, 1.1134974956512451, 1.1080149412155151, 1.1026694774627686, 1.0974563360214233, 1.0923399925231934, 1.0874747037887573, 1.0827624797821045, 1.0781898498535156, 1.0736045837402344], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 1688\", \"y\": [1.5, 1.1215180158615112, 1.114755392074585, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.0784800052642822], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 18765\", \"y\": [1.5, 1.5, 1.5, 1.1083883047103882, 1.1020805835723877, 1.0958750247955322, 1.0898069143295288, 1.0840098857879639, 1.07839035987854, 1.0729035139083862, 1.067426085472107], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 10068\", \"y\": [1.5, 1.1031196117401123, 1.0987799167633057, 1.0959177017211914, 1.093260407447815, 1.0906028747558594, 1.088037371635437, 1.085570216178894, 1.0833004713058472, 1.081152319908142, 1.5], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 15672\", \"y\": [1.5, 1.1048320531845093, 1.0969626903533936, 1.0910454988479614, 1.0853415727615356, 1.0797595977783203, 1.0742923021316528, 1.0690804719924927, 1.0640310049057007, 1.0591222047805786, 1.0542218685150146], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}, {\"name\": \"Paragraph 9373\", \"y\": [1.5, 1.0953590869903564, 1.088680624961853, 1.0837829113006592, 1.0791174173355103, 1.0745102167129517, 1.0700169801712036, 1.0657367706298828, 1.0616133213043213, 1.0576404333114624, 1.0536608695983887], \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"mode\": \"lines+markers\"}], {\"title\": \"Distances of the paragraphs to that question 4257 are getting progressed in each epoch\", \"xaxis\": {\"title\": \"Epochs\"}, \"yaxis\": {\"title\": \"Distance\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Question {} is plotted'.format(question_id_to_examine))\n",
    "paragraphs_to_plot = set(question_to_display_progress['paragraph_id'])\n",
    "data = []\n",
    "for p in paragraphs_to_plot:\n",
    "    df = question_to_display_progress[question_to_display_progress['paragraph_id'] == p].sort_values(by=['epoch', 'k'], ascending=[True, True])\n",
    "    if df.shape[0] > num_of_epochs:\n",
    "        name = 'Ground Truth {}'.format(p)\n",
    "    else:\n",
    "        name = 'Paragraph {}'.format(p)\n",
    "    df = df.drop_duplicates(subset=['question_id', 'epoch'])\n",
    "    plot_data = []\n",
    "    for _epoch in range(num_of_epochs + 1):\n",
    "        try:\n",
    "            distance = df[df['epoch'] == _epoch]['distance_to_paragraph'].values[0]\n",
    "        except:\n",
    "            distance = 1.5\n",
    "        plot_data.append((_epoch, distance))\n",
    "    plot_df = pd.DataFrame(plot_data, columns=['epoch', 'distance'])  \n",
    "    trace = go.Scatter(\n",
    "    x = plot_df.index,\n",
    "    y = plot_df['distance'],\n",
    "    mode = 'lines+markers',\n",
    "    name = name)\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Distances of the paragraphs to that question {} are getting progressed in each epoch'.format(question_id_to_examine),\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Distance'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Parahraph 15135\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:1\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:2\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:3\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:4\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:5\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:6\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:7\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:8\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:9\n",
      "There is no such a question that belongs to paragraph 15135 in that 5000 subset at epoch:0, k:10\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What is the progress of the paragraphs in which they became a ground-truth of another questions?\n",
    "# First we need to find which questions were assigned to that paragraph\n",
    "\"\"\"\n",
    "\n",
    "paragraph_ids_to_examine = [15135]\n",
    "questions = []\n",
    "for p in paragraph_ids_to_examine:\n",
    "    try:\n",
    "        print('*' * 10)\n",
    "        print('Parahraph {}'.format(p)) \n",
    "         # FOR EPOCH 0 : BEFORE APPENDIX\n",
    "        _epoch = 0\n",
    "        for _k in range(total_ks):\n",
    "            try:\n",
    "                question = np.where(data_dict['top_k'][str(_k+1)]['closest_labels_before'] \n",
    "                                                    == p)[0][_k]\n",
    "                paragraph_at_k = my_dict['top_k'][str(total_ks)]['closest_labels_before'][question][_k]\n",
    "                q_to_p_distance_at_k = my_dict['top_k'][str(total_ks)]['distances_before'][question][_k]\n",
    "                is_ground_truth_in_k_range = my_dict['top_k'][str(_k+1)]['are_founds_before'][question][0]\n",
    "                questions.append((question,\n",
    "                                 _epoch,\n",
    "                                 _k+1,\n",
    "                                 paragraph_at_k, \n",
    "                                 q_to_p_distance_at_k,\n",
    "                                 is_ground_truth_in_k_range\n",
    "                ))\n",
    "            except:\n",
    "                print('There is no such a question that belongs to paragraph {} in that 5000 subset at epoch:{}, k:{}'.format(p, _epoch, _k+1))\n",
    "\n",
    "        # FOR EPOCH > 0 : AFTER APPENDIX\n",
    "        for _epoch in range(1,num_of_epochs+1):\n",
    "            for _k in range(total_ks):\n",
    "                try:\n",
    "                    paragraph_at_k = my_dict[str(_epoch)]['top_k'][str(total_ks)]['closest_labels_after'][question][_k]\n",
    "                    q_to_p_distance_at_k = my_dict[str(_epoch)]['top_k'][str(total_ks)]['distances_after'][question][_k]\n",
    "                    is_ground_truth_in_k_range = my_dict[str(_epoch)]['top_k'][str(_k+1)]['are_founds_after'][question][0]\n",
    "                    questions.append((question,\n",
    "                                     _epoch,\n",
    "                                     _k+1,\n",
    "                                     paragraph_at_k, \n",
    "                                     q_to_p_distance_at_k,\n",
    "                                     is_ground_truth_in_k_range\n",
    "                    ))\n",
    "                except:\n",
    "                    print('There is no such a question that belongs to paragraph {} in that 5000 subset at epoch:{}, k:{}'.format(p, _epoch, _k+1))\n",
    "                \n",
    "    except:\n",
    "        print('There is no such a question that belongs to paragraph {} in that 5000 subset at epoch:{}, k:{}'.format(p, _epoch, _k+1))\n",
    "\n",
    "df_traced_questions = pd.DataFrame(questions, columns=['question_id','epoch', 'k', 'paragraph_id', 'distance_to_paragraph', 'is_ground_truth_in_k_range'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"8c9b84da-b693-4aa0-80bf-d3ec013ecb20\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8c9b84da-b693-4aa0-80bf-d3ec013ecb20\", [{\"name\": \"Question 810\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.023989081382751465, 0.02917546033859253, 0.03250598907470703, 0.035557448863983154, 0.03861957788467407, 0.041623592376708984, 0.044522881507873535, 0.047160327434539795, 0.049686312675476074, 0.052275121212005615], \"mode\": \"lines+markers\"}, {\"name\": \"Question 1534\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02072155475616455, 0.027564287185668945, 0.03213167190551758, 0.036505699157714844, 0.04076802730560303, 0.04477059841156006, 0.048480987548828125, 0.0520625114440918, 0.05556374788284302, 0.058999478816986084], \"mode\": \"lines+markers\"}, {\"name\": \"Question 1864\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02367222309112549, 0.02812778949737549, 0.0307847261428833, 0.03326117992401123, 0.035759568214416504, 0.03819847106933594, 0.040608882904052734, 0.04290032386779785, 0.04514360427856445, 0.04742705821990967], \"mode\": \"lines+markers\"}, {\"name\": \"Question 1649\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.027207612991333008, 0.033336639404296875, 0.03751415014266968, 0.041401565074920654, 0.04504579305648804, 0.04862946271896362, 0.05213040113449097, 0.05550128221511841, 0.05878090858459473, 0.06190890073776245], \"mode\": \"lines+markers\"}, {\"name\": \"Question 1001\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0409318208694458, 0.05098319053649902, 0.05772024393081665, 0.06403094530105591, 0.07021665573120117, 0.07620733976364136, 0.08190596103668213, 0.0873677134513855, 0.09268426895141602, 0.09784173965454102], \"mode\": \"lines+markers\"}, {\"name\": \"Question 4638\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.018683910369873047, 0.02339833974838257, 0.026232361793518066, 0.028917968273162842, 0.03138989210128784, 0.03375709056854248, 0.035996437072753906, 0.03801685571670532, 0.03996175527572632, 0.04185795783996582], \"mode\": \"lines+markers\"}, {\"name\": \"Question 3752\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.014843165874481201, 0.016849398612976074, 0.01837778091430664, 0.01979529857635498, 0.02114248275756836, 0.022301971912384033, 0.02349221706390381, 0.024593591690063477, 0.02565401792526245, 0.026709556579589844], \"mode\": \"lines+markers\"}, {\"name\": \"Question 3979\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0200921893119812, 0.02303212881088257, 0.02499103546142578, 0.026835739612579346, 0.02862083911895752, 0.03037172555923462, 0.03191190958023071, 0.03346610069274902, 0.034976065158843994, 0.036396682262420654], \"mode\": \"lines+markers\"}, {\"name\": \"Question 4783\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02604621648788452, 0.033604323863983154, 0.039013683795928955, 0.044145822525024414, 0.049098849296569824, 0.05385398864746094, 0.05835855007171631, 0.06257772445678711, 0.06656098365783691, 0.07049864530563354], \"mode\": \"lines+markers\"}, {\"name\": \"Question 166\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.026346266269683838, 0.03417092561721802, 0.039599478244781494, 0.04473656415939331, 0.049661099910736084, 0.05448448657989502, 0.059041619300842285, 0.06342083215713501, 0.06762152910232544, 0.07169926166534424], \"mode\": \"lines+markers\"}, {\"name\": \"Question 421\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03083711862564087, 0.03752797842025757, 0.041714370250701904, 0.045595765113830566, 0.04944753646850586, 0.05322551727294922, 0.056840598583221436, 0.06018185615539551, 0.06350332498550415, 0.06687712669372559], \"mode\": \"lines+markers\"}, {\"name\": \"Question 1053\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.008653223514556885, 0.013134777545928955, 0.017202317714691162, 0.020843923091888428, 0.024131417274475098, 0.02708137035369873, 0.0297432541847229, 0.0320395827293396, 0.03406137228012085, 0.03582119941711426], \"mode\": \"lines+markers\"}, {\"name\": \"Question 738\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.012126624584197998, 0.016644418239593506, 0.019551873207092285, 0.022308647632598877, 0.024891257286071777, 0.027406036853790283, 0.02970641851425171, 0.03195875883102417, 0.03409898281097412, 0.03613591194152832], \"mode\": \"lines+markers\"}, {\"name\": \"Question 3604\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.018518686294555664, 0.022324323654174805, 0.025202512741088867, 0.027875185012817383, 0.030402719974517822, 0.03285139799118042, 0.03515613079071045, 0.03726071119308472, 0.039218127727508545, 0.041156768798828125], \"mode\": \"lines+markers\"}, {\"name\": \"Question 1805\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.030331969261169434, 0.03551363945007324, 0.038349270820617676, 0.04103994369506836, 0.043451130390167236, 0.0457952618598938, 0.04788470268249512, 0.04991018772125244, 0.051890790462493896, 0.05378490686416626], \"mode\": \"lines+markers\"}], {\"yaxis\": {\"title\": \"Delta Distance\"}, \"xaxis\": {\"title\": \"Epochs\"}, \"title\": \"Delta Before Trained Q. Embeds. to Ground Truth vs After Trained Q. Embeds. to Ground Truth\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In each training iteration, Are questions moving closer to ground_truth or not\n",
    "if a delta value is moving to smaller value, it means question is moving to farther from its ground-truth, \n",
    "else is moving to closer to its ground-truth. The bigger, the better.\n",
    "\"\"\"\n",
    "\n",
    "data_delta = pd.DataFrame()\n",
    "for i in range(1,num_of_epochs+1):\n",
    "    data_delta[i] = my_dict[str(i)]['delta_before_after_model'][question_ids]\n",
    "data_delta = data_delta.T\n",
    "data_delta.columns = [question_ids[col_name] for col_name in data_delta.columns]\n",
    "data = []\n",
    "for q in question_ids:\n",
    "    trace = go.Scatter(\n",
    "    x = data_delta.index,\n",
    "    y = data_delta[q],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Question {}'.format(q))\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Delta Before Trained Q. Embeds. to Ground Truth vs After Trained Q. Embeds. to Ground Truth',\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Delta Distance'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"81e9644f-dd72-4fd1-906e-35f29282d9e4\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"81e9644f-dd72-4fd1-906e-35f29282d9e4\", [{\"name\": \"Top top_1\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.3372, 0.3442, 0.3438, 0.3444, 0.3456, 0.345, 0.3452, 0.3462, 0.3464, 0.346, 0.3466], \"mode\": \"lines+markers\"}, {\"name\": \"Top top_2\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.4204, 0.4272, 0.4276, 0.4284, 0.4296, 0.4296, 0.4286, 0.4282, 0.4284, 0.4294, 0.429], \"mode\": \"lines+markers\"}, {\"name\": \"Top top_5\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.5266, 0.5348, 0.5352, 0.5364, 0.5364, 0.5356, 0.5356, 0.5352, 0.5366, 0.5354, 0.5346], \"mode\": \"lines+markers\"}, {\"name\": \"Top top_10\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.597, 0.6048, 0.6052, 0.6056, 0.6068, 0.6072, 0.6072, 0.6066, 0.6064, 0.605, 0.6052], \"mode\": \"lines+markers\"}, {\"name\": \"Top top_20\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.6724, 0.6768, 0.6774, 0.6768, 0.6772, 0.677, 0.6776, 0.678, 0.6766, 0.6766, 0.676], \"mode\": \"lines+markers\"}, {\"name\": \"Top top_50\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.759, 0.7612, 0.762, 0.7626, 0.7642, 0.7636, 0.7646, 0.7634, 0.7628, 0.7636, 0.7618], \"mode\": \"lines+markers\"}], {\"yaxis\": {\"title\": \"Recall Values\"}, \"xaxis\": {\"title\": \"Epochs\"}, \"title\": \"How the recalls at top n are changing for each epoch\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"6ea16493-f4fe-4085-b964-38965481989d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"6ea16493-f4fe-4085-b964-38965481989d\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"y\": [0.11979279667139053, 0.11896759271621704, 0.11880692094564438, 0.11868074536323547, 0.11854063719511032, 0.11838176101446152, 0.11821123212575912, 0.11802074313163757, 0.11782656610012054, 0.11761912703514099, 0.11739318072795868]}], {\"yaxis\": {\"title\": \"Standart Deviation of the distances\"}, \"xaxis\": {\"title\": \"Epochs\"}, \"title\": \"Standart Deviation of the distances q to ground truths for each epoch\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Standart Deviation of the distances q to ground truths for each epoch. If it is getting smaller, which means that \n",
    "embeddings are getting look like each other\n",
    "\"\"\"\n",
    "\n",
    "data_dev = []\n",
    "data_dev.append(np.std(my_dict['distance_from_before_model_q_to_p']))\n",
    "for i in range(1,num_of_epochs+1):\n",
    "    data_dev.append(np.std(my_dict[str(i)]['distance_from_after_model_q_to_p']))\n",
    "df_dev = pd.DataFrame(data=data_dev, columns=['std_dev'])\n",
    "trace = go.Scatter(\n",
    "x = df_dev.index,\n",
    "y = df_dev['std_dev'],\n",
    "mode = 'lines+markers')\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Standart Deviation of the distances q to ground truths for each epoch',\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Standart Deviation of the distances'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=[trace], layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"b959ff89-a973-4bc7-aef9-e000403b8c9b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b959ff89-a973-4bc7-aef9-e000403b8c9b\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"type\": \"scatter\", \"mode\": \"lines+markers\", \"y\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}], {\"yaxis\": {\"title\": \"Number of bad questions\"}, \"xaxis\": {\"title\": \"Epochs\"}, \"title\": \"How many questions are getting farther from its pair paragraph\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The idea here is that how many pairs we have that their distance are getting worse means that\n",
    "they are getting farther. \n",
    "\"\"\"\n",
    "number_of_bad_questions = []\n",
    "set_bad_questions = set()\n",
    "for i in range(1,num_of_epochs+1):\n",
    "    bad_questions = np.where(my_dict[str(i)]['distance_from_after_model_q_to_p'] < 0)\n",
    "    bad_questions = my_dict[str(i)]['distance_from_after_model_q_to_p'][bad_questions]\n",
    "    number_of_bad_questions.append(bad_questions.shape[0])\n",
    "    set_bad_questions.update(bad_questions)\n",
    "    \n",
    "df_farther = pd.DataFrame(data=number_of_bad_questions, columns=['number_of_bad_questions'])\n",
    "trace = go.Scatter(\n",
    "x = df_farther.index,\n",
    "y = df_farther['number_of_bad_questions'],\n",
    "mode = 'lines+markers')\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='How many questions are getting farther from its pair paragraph',\n",
    "    xaxis=dict(\n",
    "        title='Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of bad questions'\n",
    "    )\n",
    ")\n",
    "fig =  go.Figure(data=[trace], layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
