{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackalhan/Development/github/more_meaningful_representations/venv35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "path = !echo ${VIRTUAL_ENV}\n",
    "path = os.path.join(path[0], '..')\n",
    "sys.path.append(path)\n",
    "import helper.utils as UTIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/media/jackalhan/Samsung_T5/Rethinking_Running_Data_QUASAR-T_short'\n",
    "args={\n",
    "'train_word_embeddings': 'train_word_embeddings.txt',\n",
    "'dev_word_embeddings': 'dev_word_embeddings.txt',\n",
    "'train_question_labels': 'train_question_labels.csv',\n",
    "'dev_question_labels': 'dev_question_labels.csv',\n",
    "'train_dataset_file': 'train.json',\n",
    "'dev_dataset_file': 'dev.json',\n",
    "    \n",
    "'train_paragraph_embeddings': 'train_paragraph_embeddings.hdf5',\n",
    "'train_question_embeddings': 'train_question_embeddings.hdf5',\n",
    "'dev_paragraph_embeddings': 'dev_paragraph_embeddings.hdf5',\n",
    "'dev_question_embeddings': 'dev_question_embeddings.hdf5',\n",
    "\n",
    "'ultimate_paragraph_embeddings': 'paragraph_embeddings.hdf5',\n",
    "'ultimate_question_embeddings': 'question_embeddings.hdf5',\n",
    "'ultimate_dataset_question_file': 'dataset_question_file.txt',\n",
    "'ultimate_dataset_paragraph_file': 'dataset_paragraph_file.txt',\n",
    "'ultimate_question_labels': 'question_labels.csv',\n",
    "'ultimate_word_embeddings': 'ultimate_word_embeddings.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 238/3000 [00:00<00:01, 2375.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Parsing Started\n",
      "Generating DEV examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:01<00:00, 1871.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 questions in total\n",
      "# of Paragraphs in DEV : 3000\n",
      "# of Questions in DEV : 3000\n",
      "# of Q_to_P DEV : 3000\n",
      "--------------------\n",
      "Paragraphs: Tokenization and Saving Tokenization Started in DEV\n",
      "# of Tokenized Paragraphs in DEV : 3000\n",
      "--------------------\n",
      "Questions: Tokenization and Saving Tokenization Started in DEV\n",
      "# of Tokenized Questions in DEV : 3000\n",
      "Mapping data is dumped to /media/jackalhan/Samsung_T5/Rethinking_Running_Data_QUASAR-T_short/dev_question_labels.csv\n",
      "Parsing Ended in 0.03333333333333333 minutes\n",
      "****************************************************************************************************\n",
      "Len of Dev Questions: 3000, Len of Dev Paragraphs: 3000\n",
      "****************************************************************************************************\n",
      "Parsing Started\n",
      "Generating TRAIN examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37012/37012 [00:22<00:00, 1639.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37012 questions in total\n",
      "# of Paragraphs in TRAIN : 37012\n",
      "# of Questions in TRAIN : 37012\n",
      "# of Q_to_P TRAIN : 37012\n",
      "--------------------\n",
      "Paragraphs: Tokenization and Saving Tokenization Started in TRAIN\n",
      "# of Tokenized Paragraphs in TRAIN : 37012\n",
      "--------------------\n",
      "Questions: Tokenization and Saving Tokenization Started in TRAIN\n",
      "# of Tokenized Questions in TRAIN : 37012\n",
      "Mapping data is dumped to /media/jackalhan/Samsung_T5/Rethinking_Running_Data_QUASAR-T_short/train_question_labels.csv\n",
      "Parsing Ended in 0.6333333333333333 minutes\n",
      "****************************************************************************************************\n",
      "Len of Train Questions: 37012, Len of Train Paragraphs: 37012\n"
     ]
    }
   ],
   "source": [
    "dev_tokenized_questions, \\\n",
    "dev_tokenized_paragraphs,\\\n",
    "dev_questions_nontokenized,\\\n",
    "dev_paragraphs_nontokenized = UTIL.prepare_squad_objects(os.path.join(DIR, args['dev_dataset_file']), 'DEV', \n",
    "                                                         is_dump_during_execution=True,\n",
    "                                                         mapping_file=os.path.join(DIR, args['dev_question_labels']))\n",
    "\n",
    "print('Len of Dev Questions: {}, Len of Dev Paragraphs: {}'.format(len(dev_tokenized_questions),\n",
    "                                                                  len(dev_tokenized_paragraphs)))\n",
    "\n",
    "train_tokenized_questions, \\\n",
    "train_tokenized_paragraphs,\\\n",
    "train_questions_nontokenized,\\\n",
    "train_paragraphs_nontokenized = UTIL.prepare_squad_objects(os.path.join(DIR, args['train_dataset_file']), 'TRAIN',\n",
    "                                                          is_dump_during_execution=True,\n",
    "                                                         mapping_file=os.path.join(DIR, args['train_question_labels']))\n",
    "print('Len of Train Questions: {}, Len of Train Paragraphs: {}'.format(len(train_tokenized_questions),\n",
    "                                                                  len(train_tokenized_paragraphs)))\n",
    "\n",
    "\n",
    "# ultimate_tokenized_questions = dev_tokenized_questions + train_tokenized_questions\n",
    "# ultimate_tokenized_paragraphs = dev_tokenized_paragraphs + train_tokenized_paragraphs\n",
    "# ultimate_questions_nontokenized = dev_questions_nontokenized + train_questions_nontokenized\n",
    "# ultimate_paragraphs_nontokenized = dev_paragraphs_nontokenized + train_paragraphs_nontokenized\n",
    "# print('Len of Ultimate Questions: {}, Len of Ultimate Paragraphs: {}'.format(len(ultimate_tokenized_questions),\n",
    "#                                                                   len(ultimate_tokenized_paragraphs)))\n",
    "\n",
    "# #QUESTION LABELS #\n",
    "\n",
    "# dev_question_labels = pd.read_csv(os.path.join(DIR, args['dev_question_labels']))\n",
    "# print(dev_question_labels.shape)\n",
    "# train_question_labels = pd.read_csv(os.path.join(DIR, args['train_question_labels']))\n",
    "# print(train_question_labels.shape)\n",
    "# #concate all dfs \n",
    "# frames = [dev_question_labels, train_question_labels]\n",
    "# ultimate_question_labels = pd.concat(frames, ignore_index=True)\n",
    "# del dev_question_labels, train_question_labels,frames\n",
    "# ultimate_question_labels.reset_index()\n",
    "# print(ultimate_question_labels.shape)\n",
    "\n",
    "\n",
    "# ultimate_question_labels.loc[ultimate_question_labels.index >= 10570, ['p'] ] = ultimate_question_labels + len(dev_tokenized_paragraphs)\n",
    "# ultimate_question_labels.loc[ultimate_question_labels.index >= 10570, ['q'] ] = ultimate_question_labels + len(dev_tokenized_questions)\n",
    "\n",
    "# #ultimate_question_labels[ultimate_question_labels.index >= 0]\n",
    "# ultimate_question_labels.to_csv(os.path.join(DIR, args['ultimate_question_labels']), index=False)\n",
    "\n",
    "\n",
    "# # DATASET FILES #\n",
    "\n",
    "# with open(os.path.join(DIR, args['ultimate_dataset_question_file']), 'w') as fout:\n",
    "#     for sentence in ultimate_tokenized_questions:\n",
    "#         cleaned_sentence = [word.replace('\\n', ' ') for word in sentence]\n",
    "#         fout.write(' '.join(cleaned_sentence) + '\\n')\n",
    "\n",
    "# with open(os.path.join(DIR, args['ultimate_dataset_paragraph_file']), 'w') as fout:\n",
    "#     for sentence in ultimate_tokenized_paragraphs:\n",
    "#         cleaned_sentence = [word.replace('\\n', ' ') for word in sentence]\n",
    "#         fout.write(' '.join(cleaned_sentence) + '\\n')\n",
    "\n",
    "# # DOCUMENT EMBEDDINGS #\n",
    "\n",
    "# dev_question_embeddings = UTIL.load_embeddings(os.path.join(DIR, args['dev_question_embeddings']))\n",
    "# print(dev_question_embeddings.shape)\n",
    "# train_question_embeddings = UTIL.load_embeddings(os.path.join(DIR, args['train_question_embeddings']))\n",
    "# print(train_question_embeddings.shape)\n",
    "# ultimate_question_embeddings = np.vstack((dev_question_embeddings, train_question_embeddings))\n",
    "# print(ultimate_question_embeddings.shape)\n",
    "\n",
    "# dev_paragraph_embeddings = UTIL.load_embeddings(os.path.join(DIR, args['dev_paragraph_embeddings']))\n",
    "# print(dev_paragraph_embeddings.shape)\n",
    "# train_paragraph_embeddings = UTIL.load_embeddings(os.path.join(DIR, args['train_paragraph_embeddings']))\n",
    "# print(train_paragraph_embeddings.shape)\n",
    "# ultimate_paragraph_embeddings = np.vstack((dev_paragraph_embeddings, train_paragraph_embeddings))\n",
    "# print(ultimate_paragraph_embeddings.shape)\n",
    "\n",
    "# UTIL.dump_embeddings(ultimate_question_embeddings, os.path.join(DIR, args['ultimate_question_embeddings']))\n",
    "# UTIL.dump_embeddings(ultimate_paragraph_embeddings, os.path.join(DIR, args['ultimate_paragraph_embeddings']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD EMBEDDINGS (Run 2 times, one for NOIDF, other one for WITHIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_word_embeddings = {}\n",
    "with open(os.path.join(DIR, args['dev_word_embeddings']), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        w = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        dev_word_embeddings[w] = vectors\n",
    "\n",
    "train_word_embeddings = {}\n",
    "with open(os.path.join(DIR, args['train_word_embeddings']), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        w = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        train_word_embeddings[w] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimate_word_embeddings = {}\n",
    "for w, v in train_word_embeddings.items():\n",
    "    if w not in ultimate_word_embeddings:\n",
    "        ultimate_word_embeddings[w] = v\n",
    "\n",
    "for w, v in dev_word_embeddings.items():\n",
    "    if w not in ultimate_word_embeddings:\n",
    "        ultimate_word_embeddings[w] = v   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7793356 , -2.3099442 , -0.5907096 , ...,  0.84358245,\n",
       "        0.05804019, -0.5466166 ], dtype=float32)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_word_embeddings['Which']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR, args['ultimate_word_embeddings']), 'w') as fout:\n",
    "    for w, v in ultimate_word_embeddings.items():\n",
    "        data = ' '.join(map(str, v))\n",
    "        fout.write(w + ' ' + data)\n",
    "        fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7793356  -2.3099442  -0.5907096  ...  0.84358245  0.05804019\n",
      " -0.5466166 ]\n",
      "[ 0.16745289 -0.9450648  -0.25376654 ...  0.8265831   0.31300718\n",
      " -0.47571355]\n"
     ]
    }
   ],
   "source": [
    "print(ultimate_word_embeddings['Which'])\n",
    "print(ultimate_word_embeddings['which'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ultimate_word_embeddings = {}\n",
    "with open(os.path.join(DIR, args['ultimate_word_embeddings']), 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        w = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        testing_ultimate_word_embeddings[w] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7793356  -2.3099442  -0.5907096  ...  0.84358245  0.05804019\n",
      " -0.5466166 ]\n",
      "[ 0.16745289 -0.9450648  -0.25376654 ...  0.8265831   0.31300718\n",
      " -0.47571355]\n"
     ]
    }
   ],
   "source": [
    "print(testing_ultimate_word_embeddings['Which'])\n",
    "print(testing_ultimate_word_embeddings['which'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.29759], dtype=float32)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_squared = test_word ** 2\n",
    "X_sum_squared = np.sum([X_squared], axis=1)\n",
    "X_sum_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Parsing Started\n",
      "Generating DEV examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:06<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570 questions in total\n",
      "# of Paragraphs in DEV : 2067\n",
      "# of Questions in DEV : 10570\n",
      "# of Q_to_P DEV : 10570\n",
      "--------------------\n",
      "Paragraphs: Tokenization and Saving Tokenization Started in DEV\n",
      "# of Tokenized Paragraphs in DEV : 2067\n",
      "--------------------\n",
      "Questions: Tokenization and Saving Tokenization Started in DEV\n",
      "# of Tokenized Questions in DEV : 10570\n",
      "Parsing Ended in 0.18333333333333332 minutes\n",
      "****************************************************************************************************\n",
      "Len of Dev Questions: 10570, Len of Dev Paragraphs: 2067\n",
      "****************************************************************************************************\n",
      "Parsing Started\n",
      "Generating TRAIN examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [01:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 questions in total\n",
      "# of Paragraphs in TRAIN : 18896\n",
      "# of Questions in TRAIN : 87599\n",
      "# of Q_to_P TRAIN : 87599\n",
      "--------------------\n",
      "Paragraphs: Tokenization and Saving Tokenization Started in TRAIN\n",
      "# of Tokenized Paragraphs in TRAIN : 18896\n",
      "--------------------\n",
      "Questions: Tokenization and Saving Tokenization Started in TRAIN\n",
      "# of Tokenized Questions in TRAIN : 87599\n",
      "Parsing Ended in 1.7666666666666666 minutes\n",
      "****************************************************************************************************\n",
      "Len of Train Questions: 87599, Len of Train Paragraphs: 18896\n"
     ]
    }
   ],
   "source": [
    "dev_tokenized_questions, \\\n",
    "dev_tokenized_paragraphs,\\\n",
    "dev_questions_nontokenized,\\\n",
    "dev_paragraphs_nontokenized = UTIL.prepare_squad_objects(os.path.join(DIR, args['dev_dataset_file']), 'DEV')\n",
    "\n",
    "print('Len of Dev Questions: {}, Len of Dev Paragraphs: {}'.format(len(dev_tokenized_questions),\n",
    "                                                                  len(dev_tokenized_paragraphs)))\n",
    "\n",
    "train_tokenized_questions, \\\n",
    "train_tokenized_paragraphs,\\\n",
    "train_questions_nontokenized,\\\n",
    "train_paragraphs_nontokenized = UTIL.prepare_squad_objects(os.path.join(DIR, args['train_dataset_file']), 'TRAIN')\n",
    "print('Len of Train Questions: {}, Len of Train Paragraphs: {}'.format(len(train_tokenized_questions),\n",
    "                                                                  len(train_tokenized_paragraphs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAGRAPHS ARE GETTING LOADED\n",
    "paragraph_embeddings = UTIL.load_embeddings(os.path.join(DIR,\n",
    "                                                    args['paragraph_embeddings']))\n",
    "\n",
    "# TRAIN QUESTIONS ARE GETTING LOADED\n",
    "train_question_indx = UTIL.load_embeddings(os.path.join(DIR,\n",
    "                                                        args['train_question_indx']))\n",
    "train_question_indx = train_question_indx.astype(int)\n",
    "\n",
    "train_question_label_indx = UTIL.load_embeddings(os.path.join(DIR,\n",
    "                                                         args['train_question_label_indx']))\n",
    "train_question_label_indx = train_question_label_indx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84787/84787 [43:25<00:00, 32.54it/s] \n"
     ]
    }
   ],
   "source": [
    "train_question_labels = None\n",
    "for label_indx in tqdm(train_question_label_indx):\n",
    "    train_question_label = paragraph_embeddings[label_indx, :]\n",
    "    if train_question_labels is None:\n",
    "        train_question_labels = train_question_label\n",
    "    else:\n",
    "        train_question_labels = np.vstack((train_question_labels, train_question_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_questions = dev_tokenized_questions + train_tokenized_questions\n",
    "tokenized_paragraphs = dev_tokenized_paragraphs + train_tokenized_paragraphs\n",
    "questions_nontokenized = dev_questions_nontokenized + train_questions_nontokenized\n",
    "paragraphs_nontokenized = dev_paragraphs_nontokenized + train_paragraphs_nontokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84787/84787 [00:00<00:00, 1211949.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_questions = []\n",
    "for indx in tqdm(train_question_indx):\n",
    "    train_question = questions_nontokenized[indx]\n",
    "    train_questions.append(train_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2074750ba64d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_tokenized_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_questions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_questions' is not defined"
     ]
    }
   ],
   "source": [
    "train_tokenized_questions = [question.split(' ') for question in train_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45425 vocs are created\n"
     ]
    }
   ],
   "source": [
    "indx_to_voc, voc_to_indx = UTIL.vocabulary_processor(tokenized_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_questions = UTIL.fit_vocab_to_documents(train_tokenized_questions, voc_to_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(train_tokenized_questions,\n",
    "                             maxlen=args['max_document_len'],\n",
    "                             truncating='post',\n",
    "                             padding='post',\n",
    "                             value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTIL.save_as_pickle(x_train, os.path.join(DIR, 'x_train.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTIL.save_as_pickle(voc_to_indx, os.path.join(DIR, 'voc_to_indx.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_question_indx = UTIL.load_embeddings(os.path.join(DIR,\n",
    "                                                        args['valid_question_indx']))\n",
    "valid_question_indx = valid_question_indx.astype(int)\n",
    "\n",
    "valid_question_label_indx = UTIL.load_embeddings(os.path.join(DIR,\n",
    "                                                        args['valid_question_label_indx']))\n",
    "valid_question_label_indx = valid_question_label_indx.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1057.37it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 1279843.77it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_question_labels = None\n",
    "for label_indx in tqdm(valid_question_label_indx):\n",
    "    valid_question_label = paragraph_embeddings[label_indx, :]\n",
    "    if valid_question_labels is None:\n",
    "        valid_question_labels = valid_question_label\n",
    "    else:\n",
    "        valid_question_labels = np.vstack((valid_question_labels, valid_question_label))\n",
    "\n",
    "valid_questions = []\n",
    "for indx in tqdm(valid_question_indx):\n",
    "    valid_question = questions_nontokenized[indx]\n",
    "    valid_questions.append(valid_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokenized_questions = [question.split(' ') for question in valid_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tokenized_questions = UTIL.fit_vocab_to_documents(valid_tokenized_questions, voc_to_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = sequence.pad_sequences(valid_tokenized_questions,\n",
    "                                 maxlen=args['max_document_len'],\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTIL.save_as_pickle(x_valid, os.path.join(DIR, 'x_valid.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2607108 ,  0.37758777,  0.3615227 , ..., -0.1298241 ,\n",
       "        0.46128392, -0.08047347], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 130)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK1: IF VOC ALREADY EXIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_1_DIR = '/home/jackalhan/Development/github/more_meaningful_representations/squad/train/improvement/data/'\n",
    "#TASK_1_DIR = os.path.join(DIR, 'ULTIMATE_OLD_API_with_IDF_with_1_0_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "'train_dataset_file': 'train-v1.1.json',\n",
    "'dev_dataset_file': 'dev-v1.1.json',\n",
    "\n",
    "'max_document_len': 130,\n",
    "'paragraph_embeddings': 'recall_paragraph_embeddings.hdf5',\n",
    "'train_recall_question_indx': 'train_recall_question_5000_idx.hdf5',\n",
    "'train_recall_label_indx': 'train_recall_question_5000_labels.hdf5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/48 [00:00<00:05,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Parsing Started\n",
      "Generating DEV examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:06<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570 questions in total\n",
      "# of Paragraphs in DEV : 2067\n",
      "# of Questions in DEV : 10570\n",
      "# of Q_to_P DEV : 10570\n",
      "--------------------\n",
      "Paragraphs: Tokenization and Saving Tokenization Started in DEV\n",
      "# of Tokenized Paragraphs in DEV : 2067\n",
      "--------------------\n",
      "Questions: Tokenization and Saving Tokenization Started in DEV\n",
      "# of Tokenized Questions in DEV : 10570\n",
      "Parsing Ended in 0.18333333333333332 minutes\n",
      "****************************************************************************************************\n",
      "Len of Dev Questions: 10570, Len of Dev Paragraphs: 2067\n",
      "****************************************************************************************************"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [01:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing Started\n",
      "Generating TRAIN examples...\n",
      "87599 questions in total\n",
      "# of Paragraphs in TRAIN : 18896\n",
      "# of Questions in TRAIN : 87599\n",
      "# of Q_to_P TRAIN : 87599\n",
      "--------------------\n",
      "Paragraphs: Tokenization and Saving Tokenization Started in TRAIN\n",
      "# of Tokenized Paragraphs in TRAIN : 18896\n",
      "--------------------\n",
      "Questions: Tokenization and Saving Tokenization Started in TRAIN\n",
      "# of Tokenized Questions in TRAIN : 87599\n",
      "Parsing Ended in 1.7666666666666666 minutes\n",
      "****************************************************************************************************\n",
      "Len of Train Questions: 87599, Len of Train Paragraphs: 18896\n"
     ]
    }
   ],
   "source": [
    "dev_tokenized_questions, \\\n",
    "dev_tokenized_paragraphs,\\\n",
    "dev_questions_nontokenized,\\\n",
    "dev_paragraphs_nontokenized = UTIL.prepare_squad_objects(os.path.join(TASK_1_DIR, args['dev_dataset_file']), 'DEV')\n",
    "\n",
    "print('Len of Dev Questions: {}, Len of Dev Paragraphs: {}'.format(len(dev_tokenized_questions),\n",
    "                                                                  len(dev_tokenized_paragraphs)))\n",
    "\n",
    "train_tokenized_questions, \\\n",
    "train_tokenized_paragraphs,\\\n",
    "train_questions_nontokenized,\\\n",
    "train_paragraphs_nontokenized = UTIL.prepare_squad_objects(os.path.join(TASK_1_DIR, args['train_dataset_file']), 'TRAIN')\n",
    "print('Len of Train Questions: {}, Len of Train Paragraphs: {}'.format(len(train_tokenized_questions),\n",
    "                                                                  len(train_tokenized_paragraphs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_questions = dev_tokenized_questions + train_tokenized_questions\n",
    "tokenized_paragraphs = dev_tokenized_paragraphs + train_tokenized_paragraphs\n",
    "questions_nontokenized = dev_questions_nontokenized + train_questions_nontokenized\n",
    "paragraphs_nontokenized = dev_paragraphs_nontokenized + train_paragraphs_nontokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_to_indx = UTIL.load_from_pickle(os.path.join(TASK_1_DIR, 'voc_to_indx.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45425"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc_to_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAGRAPHS ARE GETTING LOADED\n",
    "paragraph_embeddings = UTIL.load_embeddings(os.path.join(TASK_1_DIR,\n",
    "                                                    args['paragraph_embeddings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_question_indx = UTIL.load_embeddings(os.path.join(TASK_1_DIR,\n",
    "                                                        args['train_recall_question_indx']))\n",
    "train_recall_question_indx = train_recall_question_indx.astype(int)\n",
    "\n",
    "train_recall_question_label_indx = UTIL.load_embeddings(os.path.join(TASK_1_DIR,\n",
    "                                                        args['train_recall_label_indx']))\n",
    "train_recall_question_label_indx = train_recall_question_label_indx.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1119.38it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 1354749.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train_recall_question_labels = None\n",
    "for label_indx in tqdm(train_recall_question_label_indx):\n",
    "    train_recall_question_label = paragraph_embeddings[label_indx, :]\n",
    "    if train_recall_question_labels is None:\n",
    "        train_recall_question_labels = train_recall_question_label\n",
    "    else:\n",
    "        train_recall_question_labels = np.vstack((train_recall_question_labels, train_recall_question_label))\n",
    "\n",
    "train_recall_questions = []\n",
    "for indx in tqdm(train_recall_question_indx):\n",
    "    train_recall_question = questions_nontokenized[indx]\n",
    "    train_recall_questions.append(train_recall_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_tokenized_questions = [question.split(' ') for question in train_recall_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'what', 'year', 'did', 'Bermuda', 'enter', 'British', 'rule', '?']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recall_tokenized_questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_tokenized_questions = UTIL.fit_vocab_to_documents(train_recall_tokenized_questions, voc_to_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[236, 46, 54, 14, 33127, 982, 1087, 1592, 11]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recall_tokenized_questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_to_indx['In']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_recall = sequence.pad_sequences(train_recall_tokenized_questions,\n",
    "                                 maxlen=args['max_document_len'],\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  245,    14,   869, ...,     0,     0,     0],\n",
       "       [  236,    46,    54, ...,     0,     0,     0],\n",
       "       [   18,   336,    58, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [   37,    20, 34508, ...,     0,     0,     0],\n",
       "       [  236,    46,  6636, ...,     0,     0,     0],\n",
       "       [   18,    32,     5, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTIL.save_as_pickle(x_train_recall, os.path.join(TASK_1_DIR, 'x_train_valid.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK2: CONVERT QUESTION_LABELS. HDF5 to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_2_DIR = '/home/jackalhan/Development/github/more_meaningful_representations/squad/train/improvement/data/ULTIMATE_OLD_API_with_1_0_0'\n",
    "labels_as_h5py_file_name = 'train_question_labels.hdf5'\n",
    "labels_as_h5py_file = os.path.join(TASK_2_DIR, labels_as_h5py_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_as_h5py = UTIL.load_embeddings(labels_as_h5py_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_as_h5py = labels_as_h5py.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(labels_as_h5py, columns=['p']).to_csv(os.path.join(TASK_2_DIR, 'question_labels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK3: L2 CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_3_DIR = '/home/jackalhan/Development/github/more_meaningful_representations/squad/dev/ELMO_CONTEXT_OLD_API_EMBEDDINGS'\n",
    "h5py_file_name1 = 'dev_token_embeddings_old_api_doc_0.hdf5'\n",
    "h5py_file_name2 = 'dev_token_embeddings_old_api_doc_1.hdf5'\n",
    "h5py_file1 = UTIL.load_embeddings(os.path.join(TASK_3_DIR, h5py_file_name1))\n",
    "h5py_file2 = UTIL.load_embeddings(os.path.join(TASK_3_DIR, h5py_file_name2))\n",
    "h5py_file3 = UTIL.load_embeddings('/media/jackalhan/Extreme 500/ULTIMATE_OLD_API_with_1_0_0_L2/dev_question_embeddings.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py_file = np.vstack((h5py_file1, h5py_file2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 3, 1024)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7793356 , -2.3099442 , -0.5907096 , ...,  0.84358245,\n",
       "         0.05804019, -0.5466166 ],\n",
       "       [ 0.7555715 , -0.37882742,  0.10019857, ...,  0.45271248,\n",
       "        -0.03817607, -0.68883264],\n",
       "       [ 0.31546307, -0.14667389, -0.27995116, ..., -0.08131212,\n",
       "         0.32476687, -0.18639295],\n",
       "       ...,\n",
       "       [ 0.10457286,  0.3696899 , -1.2471359 , ..., -0.12930577,\n",
       "        -0.02476517, -0.06765284],\n",
       "       [-0.24508505,  0.28492582, -0.29489422, ...,  0.16593422,\n",
       "        -1.1265616 , -0.21003507],\n",
       "       [-1.1727259 ,  0.22724494, -1.5357871 , ...,  1.0646051 ,\n",
       "         0.27659285,  0.7338671 ]], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py_file[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = h5py_file[0,1,:]\n",
    "x = np.reshape(x, (1,1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1024)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1024)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00038471, -0.00580528, -0.01100152, ...,  0.01517917,\n",
       "         0.00184055, -0.00921226],\n",
       "       [-0.00013369, -0.00914192, -0.01381616, ...,  0.0171214 ,\n",
       "         0.0003133 , -0.00878628],\n",
       "       [ 0.01117491, -0.01330363,  0.00180931, ...,  0.00488911,\n",
       "        -0.00469446,  0.00674144],\n",
       "       ...,\n",
       "       [ 0.00914114,  0.00754567, -0.01404146, ..., -0.00160104,\n",
       "         0.0135705 ,  0.00185585],\n",
       "       [ 0.00043095, -0.00216133, -0.00534114, ...,  0.00170421,\n",
       "         0.00086083, -0.01188126],\n",
       "       [-0.00669443,  0.00216011,  0.00088808, ...,  0.00402101,\n",
       "         0.01271245, -0.00432279]], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py_file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = preprocessing.normalize(h5py_file3, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00113517, -0.01712958, -0.03246208, ...,  0.04478905,\n",
       "         0.00543091, -0.02718254],\n",
       "       [-0.0003949 , -0.02700318, -0.04080984, ...,  0.05057276,\n",
       "         0.00092542, -0.02595271],\n",
       "       [ 0.03100294, -0.03690875,  0.00501963, ...,  0.01356402,\n",
       "        -0.01302401,  0.01870303],\n",
       "       ...,\n",
       "       [ 0.03508054,  0.02895767, -0.0538863 , ..., -0.00614423,\n",
       "         0.05207889,  0.00712211],\n",
       "       [ 0.00152789, -0.00766276, -0.01893638, ...,  0.00604208,\n",
       "         0.00305197, -0.04212362],\n",
       "       [-0.02563315,  0.00827113,  0.00340048, ...,  0.01539655,\n",
       "         0.0486763 , -0.01655209]], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_squared = X_normalized ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sum_squared = np.sum(X_squared, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99999994, 0.9999999 , ..., 0.99999994, 0.9999998 ,\n",
       "       1.        ], dtype=float32)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sum_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10570, 1024)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_squared = h5py_file3 ** 2\n",
    "X_squared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sum_squared = np.sum(X_squared, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11485567, 0.11461592, 0.12992178, ..., 0.06789973, 0.07955605,\n",
       "       0.06820612], dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sum_squared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
