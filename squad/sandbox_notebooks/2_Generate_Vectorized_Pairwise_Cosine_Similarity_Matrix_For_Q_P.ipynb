{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_type = 'train'\n",
    "dataset_type = 'dev'\n",
    "dataset_version = 'v1.1'\n",
    "\n",
    "index_field = ['Unnamed: 0']\n",
    "\n",
    "# required files\n",
    "_basepath = '/home/jackalhan/Development/github/more_meaningful_representations/squad/'\n",
    "datadir = os.path.join(_basepath, dataset_type)\n",
    "modeldir = os.path.join(_basepath, 'model')\n",
    "\n",
    "_qas_file_name = '{}_qas.csv'.format(dataset_type)\n",
    "qas_file = os.path.join(datadir, _qas_file_name)\n",
    "\n",
    "_embedding_mean_paragraph_file_as_h5py_name = 'elmo_{}_mean_paragraph_embeddings.hdf5'\n",
    "embedding_mean_paragraph_file_as_h5py = os.path.join(datadir, _embedding_mean_paragraph_file_as_h5py_name)\n",
    "\n",
    "_embedding_mean_question_file_as_h5py_name = 'elmo_{}_mean_question_embeddings.hdf5'\n",
    "embedding_mean_question_file_as_h5py = os.path.join(datadir, _embedding_mean_question_file_as_h5py_name)\n",
    "\n",
    "_cos_similarity_results_file_name =  '{}_cos_similarity_with_{}_norm_for_q_vs_para.csv'\n",
    "cos_similarity_results_file_name = os.path.join(datadir, _cos_similarity_results_file_name)\n",
    "\n",
    "_nearest_all_cos_similarity_results_file_name =  '{}_nearest_all_cos_similarity_with_{}_norm_for_q_vs_para.csv'\n",
    "nearest_all_cos_similarity_results_file = os.path.join(datadir, _nearest_all_cos_similarity_results_file_name)\n",
    "\n",
    "_cos_similarity_results_as_hist_file_name =  'histogram_{}_cos_similarity_with_{}_norm_for_q_vs_para.png'\n",
    "cos_similarity_results_as_hist_file = os.path.join(datadir, _cos_similarity_results_as_hist_file_name)\n",
    "\n",
    "_paragraphs_file_name_as_txt = '{}_paragraphs.txt'.format(dataset_type)\n",
    "paragraphs_file_as_txt = os.path.join(datadir, _paragraphs_file_name_as_txt)\n",
    "\n",
    "_questions_file_name_as_txt = '{}_questions.txt'.format(dataset_type)\n",
    "questions_file_as_txt = os.path.join(datadir, _questions_file_name_as_txt)\n",
    "\n",
    "df_qas = pd.read_csv(qas_file).set_index(index_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_look_up = []\n",
    "q_look_up = []\n",
    "with open(paragraphs_file_as_txt, 'r') as fp_in,open(questions_file_as_txt, 'r') as fq_in:\n",
    "    for i, line in enumerate(fp_in):\n",
    "        p_look_up.append((i, line.replace('\\n','')))\n",
    "    for i, line in enumerate(fq_in):\n",
    "        q_look_up.append((i, line.replace('\\n','')))\n",
    "df_p_look_up = pd.DataFrame(data=p_look_up, columns=['id', 'paragraph']).set_index('id')\n",
    "df_q_look_up = pd.DataFrame(data=q_look_up, columns=['id', 'question']).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 1024\n",
    "items = [dict({'type':'questions', \n",
    "                     'source_file':embedding_mean_question_file_as_h5py\n",
    "                     }), \n",
    "              dict({'type':'paragraphs', \n",
    "                     'source_file':embedding_mean_paragraph_file_as_h5py,\n",
    "                     })\n",
    "              ]\n",
    "\n",
    "for norm_type in ['l2']:\n",
    "    print(10*'*', norm_type.upper(),'NORM', 10*'*')\n",
    "    for vals in items:\n",
    "        print(vals['type'], 'are getting processed!!!')\n",
    "        vals['matrix'] = np.empty((0, dims), dtype=float)\n",
    "        with h5py.File(vals['source_file'].format(norm_type), 'r') as fin:        \n",
    "            for _ in tqdm_notebook(fin, total=len(fin)):             \n",
    "                vec = np.reshape(np.array(fin[str(_)][...]), (1,dims))                                   \n",
    "                vals['matrix'] = np.append(vals['matrix'], vec, axis=0)\n",
    "            \n",
    "    QUES = items[0]['matrix']\n",
    "    print('QUES Shape', QUES.shape)\n",
    "    PARA = items[1]['matrix']\n",
    "    print('PARA Shape', PARA.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for norm_type in ['l2']:\n",
    "    print('Similarities are getting calculated !!!')\n",
    "    results = []\n",
    "    nearest_paragraphs = []\n",
    "    for q_id, _ in enumerate(tqdm_notebook(QUES, total=len(QUES))):\n",
    "        question = df_q_look_up[df_q_look_up.index == q_id].values[0][0]\n",
    "        q_vec = np.array([_]) \n",
    "        sk_sim = cosine_similarity(q_vec,PARA)[0]\n",
    "        actual_paragraph_id = df_qas[df_qas['Question_Id'] == q_id]['Paragraph_Id'].values[0]\n",
    "        similarities = np.argsort(-sk_sim)\n",
    "        order_of_the_actual_paragraph_id = np.where(similarities == actual_paragraph_id)[0][0] + 1\n",
    "        calculated_most_similar_1_paragraph = similarities[0]\n",
    "        results.append((q_id, actual_paragraph_id,  \n",
    "                        order_of_the_actual_paragraph_id, \n",
    "                        sk_sim[actual_paragraph_id], \n",
    "                        calculated_most_similar_1_paragraph, \n",
    "                        sk_sim[calculated_most_similar_1_paragraph]))\n",
    "        for i, nearest_paragraph_id in enumerate(similarities[0:5]):\n",
    "            nearest_paragraphs.append((question, \n",
    "                                       df_p_look_up[df_p_look_up.index == nearest_paragraph_id].values[0][0],\n",
    "                                       i+1, \n",
    "                                       sk_sim[nearest_paragraph_id] ))\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nearest_paragraphs = pd.DataFrame(data=nearest_paragraphs, columns=['question', 'paragraph', 'nearest_order', 'cos_similarity'])\n",
    "df_nearest_paragraphs.to_csv(nearest_all_cos_similarity_results_file.format(dataset_type, norm_type), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results= pd.DataFrame(data=results, columns=['Question_Id', 'Actual_Paragraph_Id', \n",
    "                                             'Order Index of Actual_Paragraph_Id in Similarities List',\n",
    "                                             'Similarity Score for Actual_Paragraph_Id',\n",
    "                                             'Calculated Top 1 Most Similar Paragraph', \n",
    "                                             'Similarity Score for Most Similar Paragraph'\n",
    "                                            ])\n",
    "\n",
    "df_results.to_csv(cos_similarity_results_file_name.format(dataset_type, norm_type), index=False)\n",
    "ax = df_results['Order Index of Actual_Paragraph_Id in Similarities List'].hist()\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(cos_similarity_results_as_hist_file.format(dataset_type, norm_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('/home/jackalhan/Development/github/more_meaningful_representations/squad/dev/dev_neighbors.csv')\n",
    "ax = df_results['actual_paragraph_order'].hist()\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/home/jackalhan/Development/github/more_meaningful_representations/squad/dev/dev_neighbors_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_filtered=df_results.drop_duplicates(['question'])\n",
    "df_results_filtered.to_csv('/home/jackalhan/Development/github/more_meaningful_representations/squad/dev/dev_neighbors_removed_duplicates_q.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_results_filtered['actual_paragraph_order'].hist()\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('/home/jackalhan/Development/github/more_meaningful_representations/squad/dev/dev_neighbors_removed_duplicates_q_hist.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
